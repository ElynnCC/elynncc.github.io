[{"authors":["admin"],"categories":null,"content":"I am an Assistant Professor of Technology, Operations and Statistics (TOPS) at NYU Stern School of Business. I am generally interested in developing novel methodologies for data-driven decision-making and complex data analysis, with applications in business, economics and health care. My work has been applied to international trade, corporate finance, clinical dynamic treatments and has been recognized by NSF Postdoc Award DMS-1803241.\nBefore joining NYU Stern, I worked as a postdoctoral fellow, advised by Prof. Michael I. Jordan, at the Department of Computer Sciences, University of California, Berkeley. I also spent one year as a postdoctoral fellow at ORFE, Princeton University, working with Prof. Jianqing Fan. I received my Ph.D. in Statistics from Rutgers University, advised by Prof. Rong Chen.\nOur research group is currently engaged in several exciting projects focused on tensor learning, reinforcement learning, and transfer learning. We are actively seeking highly motivated individuals to join our team. For more information about the ongoing research and potential student opportunities, please visit the Research and Students sections on our website. We look forward to hearing from talented individuals interested in contributing to our research endeavors.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4036ab9376e924db20b9e42fb1307811","permalink":"/authors/authors/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/authors/","section":"authors","summary":"I am an Assistant Professor of Technology, Operations and Statistics (TOPS) at NYU Stern School of Business. I am generally interested in developing novel methodologies for data-driven decision-making and complex data analysis, with applications in business, economics and health care. My work has been applied to international trade, corporate finance, clinical dynamic treatments and has been recognized by NSF Postdoc Award DMS-1803241.\nBefore joining NYU Stern, I worked as a postdoctoral fellow, advised by Prof.","tags":null,"title":"Elynn Chen","type":"authors"},{"authors":[],"categories":null,"content":" Slides can be added in a few ways:\nCreate slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["admin"],"categories":["research"],"content":"Why Tensors? Tensors provide a more natural and richer representation of the multi-dimensional physical world, and thus have great potentials to increase statistical and computational efficiency, and facilitate insightful scientific, social and economic discoveries, which cannot be achieved by the classic multivariate, or vector-based, statistical methods.\nTensor Unsupervised Learning Tensor Supervised Learning Beyond \u0026hellip; During my Ph.D., I initiated this line of research, and you can find many of my recent papers on tensor learning on my Google Scholar page. We are actively engaged in various related projects and would be delighted to discuss them further with you. If you are interested, please feel free to contact me without hesitation.\n","date":1675296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675296000,"objectID":"4386e6a954f4cb3be7f531f588906156","permalink":"/research/tensor-learning/","publishdate":"2023-02-02T00:00:00Z","relpermalink":"/research/tensor-learning/","section":"research","summary":"Developing efficient algorithms for tensor data is my primary focus, as tensors offer a more natural and comprehensive representation of the multi-dimensional physical world. My aim is to enhance the understanding and analysis of complex data structures through innovative approaches.","tags":["Tensor Learning"],"title":"Tensor Learning","type":"research"},{"authors":["Elynn Chen","Rui Song","Michael I. Jordan"],"categories":null,"content":"","date":1661990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661990400,"objectID":"2b59e7ae81939ffd90b0cddb31b14144","permalink":"/publication/chen-2020-heterorl/","publishdate":"2022-09-01T00:00:00Z","relpermalink":"/publication/chen-2020-heterorl/","section":"publication","summary":"","tags":null,"title":"Reinforcement Learning with Heterogeneous Data","type":"publication"},{"authors":["Elynn Chen","Jianqing Fan","Xuening Zhu"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"fe817c26f2977034c55e65e235c41c0b","permalink":"/publication/chen-2019-group-nar/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/chen-2019-group-nar/","section":"publication","summary":"","tags":null,"title":"Community Network Auto-Regression for High-Dimensional Time Series","type":"publication"},{"authors":["admin"],"categories":["research"],"content":"RL under a Heterogeneous Social Environment Reinforcement Learning holds great promise for data-driven decision-making in various social contexts, including healthcare, education, and business. However, classical methods that focus on the mean of the total return may yield misleading results when dealing with heterogeneous populations typically found in large-scale datasets. To address this issue, we introduce $K$-Heterogeneous Markov Decision Process, a framework designed to handle sequential decision problems with latent population heterogeneity. Within this framework, we propose auto-clustered policy evaluation for estimating the value of a given policy and auto-clustered policy iteration for estimating the optimal policy within a parametric policy class. Our auto-clustered algorithms can automatically identify homogeneous subpopulations while simultaneously estimating the action value function and the optimal policy for each subgroup. We establish convergence rates and construct confidence intervals for the estimators. Simulation results support our theoretical findings, and an empirical study conducted on a real medical dataset confirms the presence of value heterogeneity and validates the advantages of our novel approach.\nYou can access the most recent version of our paper at the following link: https://arxiv.org/abs/2202.00088. We are currently working on several related projects and would be happy to discuss them with you. If you are interested, please don\u0026rsquo;t hesitate to reach out to us.\n","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"70acc0e810726367fabb17ca20acec29","permalink":"/research/reinforcement-learning/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/research/reinforcement-learning/","section":"research","summary":"My research focuses on the design and development of reinforcement learning (RL) algorithms tailored for social applications in various domains, including business, education, and healthcare. By leveraging RL techniques, my collaborators and I aim to address specific challenges and opportunities that arise in these social contexts. Our goal is to create novel algorithms that can effectively optimize decision-making processes, improve outcomes, and contribute to the advancement of social applications.","tags":["RL"],"title":"RL for Social Decisions","type":"research"},{"authors":["Elynn Chen","Jianqing Fan"],"categories":null,"content":"","date":1632787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632787200,"objectID":"a91174272f445865679b5041df0bc135","permalink":"/publication/chen-2019-inference/","publishdate":"2019-06-01T13:57:37.519234Z","relpermalink":"/publication/chen-2019-inference/","section":"publication","summary":"","tags":null,"title":"Statistical Inference for High-Dimensional Matrix-Variate Factor Models","type":"publication"},{"authors":["admin"],"categories":["research"],"content":"Transferred $Q$-Learning We consider $Q$-learning with knowledge transfer, using samples from a target reinforcement learning (RL) task as well as source samples from different but related RL tasks. We propose transfer learning algorithms for both batch and online $Q$-learning with offline source studies. The proposed transferred $Q$-learning algorithm contains a novel {\\em re-targeting} step that enables {\\em vertical information-cascading} along multiple steps in an RL task, besides the usual horizontal information-gathering as transfer learning (TL) for supervised learning. We establish the first theoretical justifications of TL in RL tasks by showing a faster rate of convergence of the $Q$-function estimation in the offline RL transfer, and a lower regret bound in the offline-to-online RL transfer under certain similarity assumptions. Empirical evidences from both synthetic and real datasets are presented to backup the proposed algorithm and our theoretical results.\nYou can access the most recent version of our paper at the following link: https://arxiv.org/abs/2202.04709. We are currently working on several related projects and would be happy to discuss them with you. If you are interested, please don\u0026rsquo;t hesitate to reach out to us.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"2462a0969bb8da30adc7ae41771d5fe2","permalink":"/research/transfer-learning/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/research/transfer-learning/","section":"research","summary":"My research centers around the concept of transferring knowledge from one or more source tasks to enhance learning performance in a target task. In particular, I focus on the application of transfer learning in the domains of reinforcement learning and tensor learning. By leveraging knowledge gained from related tasks, my collaborators and I aim to improve the efficiency and effectiveness of learning processes.","tags":["Transfer Learning"],"title":"Transfer Learning","type":"research"},{"authors":["Elynn Chen","Ruey S. Tsay","Rong Chen"],"categories":null,"content":"","date":1605657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605657600,"objectID":"8e2277686ed201b9fa370e6b35140bb8","permalink":"/publication/chen-2019-constrained/","publishdate":"2019-06-01T13:57:37.519234Z","relpermalink":"/publication/chen-2019-constrained/","section":"publication","summary":"","tags":null,"title":"Constrained Factor Models for High-Dimensional Matrix-Variate Time Series","type":"publication"},{"authors":["Elynn Chen","Dong Xia","Chencheng Cai","Jianqing Fan"],"categories":null,"content":"","date":1604793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604793600,"objectID":"ab6cfa79bda8ce815783a2fddba8fef9","permalink":"/publication/chen-2019-proj-tucker/","publishdate":"2020-11-08T00:00:00Z","relpermalink":"/publication/chen-2019-proj-tucker/","section":"publication","summary":"","tags":null,"title":"Semiparametric Tensor Factor Analysis by Iteratively Projected SVD","type":"publication"},{"authors":["Tianyi Lin","Zeyu Zheng","Elynn Chen","Marco Cuturi","Michael I. Jordan"],"categories":null,"content":"","date":1604275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604275200,"objectID":"f5eee1b4819d69bd50b071467b5ecc28","permalink":"/publication/lin-2020-prw/","publishdate":"2020-11-02T00:00:00Z","relpermalink":"/publication/lin-2020-prw/","section":"publication","summary":"","tags":null,"title":"On Projection Robust Optimal Transport: Sample Complexity and Model Misspecification","type":"publication"},{"authors":["Xialu Liu","Elynn Chen"],"categories":null,"content":"","date":1599004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599004800,"objectID":"d6713144414371d6659f2f79f5e2ce46","permalink":"/publication/liu-2019-thresholdmfm/","publishdate":"2020-09-02T00:00:00Z","relpermalink":"/publication/liu-2019-thresholdmfm/","section":"publication","summary":"","tags":null,"title":"Estimation and Inference of High-Dimensional Matrix-Valued Threshold Factor Models","type":"publication"},{"authors":["Sai Li","Elynn Chen","Michael I. Jordan"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"c41443ba110a992376d967187ab1f8f5","permalink":"/publication/chen-2020-hdbandits/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/publication/chen-2020-hdbandits/","section":"publication","summary":"","tags":null,"title":"High-Dimensional Structured Bandits: Minimax Regret, Estimation and Inference","type":"publication"},{"authors":["Elynn Chen","Sai Li","Michael I. Jordan"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"66e9e4cbb25d54ffcb72eed7365e9d64","permalink":"/publication/chen-2020-transq/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/publication/chen-2020-transq/","section":"publication","summary":"","tags":null,"title":"Transferred $Q$ Learning","type":"publication"},{"authors":["Elynn Chen","Xin Yun","Rong Chen","Qiwei Yao"],"categories":null,"content":"","date":1576627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576627200,"objectID":"75442ed09b94084c7c75219b9b99cd92","permalink":"/publication/chen-2017-multivariate/","publishdate":"2019-06-02T02:10:20.461668Z","relpermalink":"/publication/chen-2017-multivariate/","section":"publication","summary":"","tags":null,"title":"Modeling Multivariate Spatial-Temporal Data with Latent Low-Dimensional Dynamics","type":"publication"},{"authors":["admin"],"categories":["concepts"],"content":"Starting with the linear classifier Model Linear classifier computes scores $s = W x$ for $k$ different visual categories given the image, where $W$ was a matrix and $x$ was an input column vector containing all pixel data of the image. In the case of CIFAR-10, $x$ is a [3072x1] column vector, and $W$ is a [10x3072] matrix, so that the output scores is a vector of 10 class scores.\nMathmetical formulation. Given labeled data set ${\\bx_i, y_i}_{1 \\le i \\le n}$ where $\\bx_i \\in \\mathbb{R}^p$ being the $p$-dimensional feature of sample $i$ and $y_i \\in {1, \\cdots, K}$ being the ground-truth label. We wish to learn a classifier that labels an new observation $\\bx \\in \\mathbb{R}^p$ with label $y$.\nA linear classifier computes a $K$ dimensional score vector $ \\bs = \\bW \\bx $. Each entry $s_k = \\bW_{k, \\cdot}^\\top \\bx$, $1 \\le k \\le K$ is a score for the $k$-th class. Every row of $\\bW$ is a classifier for one of the classes. In statistics, logistic regression can be used to build a 2-class classifier, which corresponds to one row of $\\bW$.\nThe predicted label $y = \\underset{\\arg \\max}{k} s_k$.\nBias trick. The genral score function is defined as\n$$ f(\\bx_i, \\bW, \\bb) = \\bW \\bx_i + \\bb. $$\nHowever, it is a little cumbersome to keep track of two sets of parameters (the biases (intercept) $\\bb$ and weights (slope) $\\bW$) separately. A commonly used trick is to combine the two sets of parameters into a single matrix that holds both of them by extending the vector $\\bx_i$ with one additional dimension that always holds the constant 1 - a default bias dimension. With the extra dimension, the new score function will simplify to a single matrix multiply:\n$$ f(\\bx_i, W) = \\bW \\bx_i. $$\nData preprocessing. In Machine Learning, it is a very common practice to always perform normalization of your input features (in the case of images, every pixel is thought of as a feature). In particular, it is important to center your data by subtracting the mean from every feature. Further common preprocessing is to scale each input feature so that its values range from [-1, 1]. Of these, zero mean centering is arguably more important but we will have to wait for its justification until we understand the dynamics of gradient descent.\nEstimation Building a classifier boils down to estimate parameter $\\bW$ based on observed samples ${\\bx_i, y_i}_{1 \\le i \\le n}$. A common method in machine learning is to minimize some loss function of the descrepency between the predicted label $\\hat{y}_i$ and the ground truth $y_i$. The loss function quantifies our unhappiness with predictions on the training set.\nDiffirent definitions of the loss function lead to different classification methods. In the following, we will consider two commonly seen classifiers \u0026ndash; the SVM and Softmax classifier.\nMulticlass Support Vector Machine loss A commonly used loss is called the Multiclass Support Vector Machine (SVM) loss. The Multiclass SVM loss for the i-th sample is formalized as follows:\n$$ L_i = \\sum_{j\\neq y_i} \\max(0, s_j - s_{y_i} + \\Delta) $$\nRemark.\nNote that $$ \\max(0, s_j - s_{y_i} + \\Delta) = \\begin{pmatrix} 0, if s_{y_i} \\ge s_j + \\Delta, \\ positive, if s_{y_i} \u0026lt; s_j + \\Delta \\end{pmatrix}. $$\n$L-i$ achieves its minimal value 0 when the classifier gives the correct label, that is, when $s_{y_i} \\ge s_j + \\Delta$ for any $j \\ne y_i$.\nThe threshold at zero $max(0,-)$ function is often called the hinge loss. The squared hinge loss SVM (or L2-SVM) uses the form $(max(0,-)^2$ that penalizes violated margins more strongly (quadratically instead of linearly). The unsquared version is more standard, but in some datasets the squared hinge loss can work better. This can be determined during cross-validation.\nRegularization. Note that the $\\hat{\\bW}$ minimizing $L_i$ is not unique when the classifier with $\\hat{\\bW}$ correctly classify every example (i.e. all scores are so that all the margins are met, and $L_i = 0$ for all i). Any multiple of these parameters $\\lambda W$ where $\\lambda \u0026gt; 1$ will also give zero loss because this transformation uniformly stretches all score magnitudes and hence also their absolute differences. We wish to encode some preference for a certain set of weights $\\bW$ over others to remove this ambiguity. We can do so by extending the loss function with a regularization penalty $R(W)$. The most common regularization penalty is the L2 norm that discourages large weights through an elementwise quadratic penalty over all parameters:\n$$ R(\\bW) = \\norm{\\bW}^2_F. $$\nIncluding the regularization penalty completes the full Multiclass Support Vector Machine loss, which is made up of two components: the data loss (which is the average loss $L_i$ over all examples) and the regularization loss. That is, the full Multiclass SVM loss becomes:\n$$ L = \\underbrace{ \\frac{1}{N} \\sum_i L_i }\\text{data loss} + \\underbrace{ \\lambda R(W) }\\text{regularization loss}, $$\nwhere \\(N\\) is the number of training examples. Hyperparameter $\\lambda$ is usually determined by cross-validation.\nRemark.\nIn addition to the motivation above there are many desirable properties to include the regularization penalty. For example, it turns out that including the L2 penalty leads to the appealing max margin property in SVMs (See CS229 lecture notes for full details).\nThe most appealing property is that penalizing large weights tends to improve generalization, because it means that no input dimension can have a very large influence on the scores all by itself. Since the L2 penalty prefers smaller and more diffuse weight vectors, the final classifier is encouraged to take into account all input dimensions to small amounts rather than a few input dimensions and very strongly. As we will see later in the class, this effect can improve the generalization performance of the classifiers on test images and lead to less overfitting.\nThe biases do not have the same effect since, unlike the weights, they do not control the strength of influence of an input dimension.\nDue to the regularization penalty we can never achieve loss of exactly 0.0 on all examples, because this would only be possible in the pathological setting of $\\bW = 0$.\nMaking good predictions on the training set is equivalent to minimizing the loss. All we have to do now is to come up with a way to find the weights that minimize the loss.\nLater. Leave the code and practical considerations of SVM to later study.\nSoftmax classifier The Softmax classifier is a generalization of the binary Logistic Regression classifier to multiple classes. Unlike the SVM which treats the outputs $f(x_i,W)$ as (uncalibrated and possibly difficult to interpret) scores for each class, the Softmax classifier gives a slightly more intuitive output (normalized class probabilities) and also has a probabilistic interpretation explained later. In the Softmax classifier, the scores $f(x_i; W) = W x_i$ are now interpreted as the unnormalized log probabilities for each class, that is $\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }$ is the probability that $y_i$ is the correct label. Thus, for the grounth truth to be choosen, we need to maximize $\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }$. This can be achieved by using the cross-entropy loss\n$$ L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right) \\hspace{0.5in} \\text{or equivalently} \\hspace{0.5in} L_i = -f_{y_i} + \\log\\sum_j e^{f_j} $$\nAs before, the full loss for the dataset is the mean of \\(L_i\\) over all training examples together with a regularization term \\(R(W)\\). The function \\(f_j(z) = \\frac{e^{z_j}}{\\sum_k e^{z_k}} \\) is called the softmax function: It takes a vector of arbitrary real-valued scores (in \\(z\\)) and squashes it to a vector of values between zero and one that sum to one. The full cross-entropy loss that involves the softmax function might look scary if you\u0026rsquo;re seeing it for the first time but it is relatively easy to motivate.\nInformation theory view. The cross-entropy between a \u0026ldquo;true\u0026rdquo; distribution \\(p\\) and an estimated distribution \\(q\\) is defined as:\n$$ H(p,q) = - \\sum_x p(x) \\log q(x) $$\nThe Softmax classifier is hence minimizing the cross-entropy between the estimated class probabilities ( \\(q = e^{f_{y_i}} / \\sum_j e^{f_j} \\) as seen above) and the \u0026ldquo;true\u0026rdquo; distribution, which in this interpretation is the distribution where all probability mass is on the correct class (i.e. \\(p = [0, \\ldots 1, \\ldots, 0]\\) contains a single 1 at the \\(y_i\\) -th position.). Moreover, since the cross-entropy can be written in terms of entropy and the Kullback-Leibler divergence as \\(H(p,q) = H(p) + D_{KL}(p||q)\\), and the entropy of the delta function \\(p\\) is zero, this is also equivalent to minimizing the KL divergence between the two distributions (a measure of distance). In other words, the cross-entropy objective wants the predicted distribution to have all of its mass on the correct answer.\nProbabilistic interpretation. Looking at the expression, we see that\n$$ P(y_i \\mid x_i; W) = \\frac{e^{f_{y_i}}}{\\sum_j e^{f_j} } $$\ncan be interpreted as the (normalized) probability assigned to the correct label \\(y_i\\) given the image \\(x_i\\) and parameterized by \\(W\\). To see this, remember that the Softmax classifier interprets the scores inside the output vector \\(f\\) as the unnormalized log probabilities. Exponentiating these quantities therefore gives the (unnormalized) probabilities, and the division performs the normalization so that the probabilities sum to one. In the probabilistic interpretation, we are therefore minimizing the negative log likelihood of the correct class, which can be interpreted as performing Maximum Likelihood Estimation (MLE). A nice feature of this view is that we can now also interpret the regularization term \\(R(W)\\) in the full loss function as coming from a Gaussian prior over the weight matrix \\(W\\), where instead of MLE we are performing the Maximum a posteriori (MAP) estimation. We mention these interpretations to help your intuitions, but the full details of this derivation are beyond the scope of this class.\nPractical issues: Numeric stability. When you\u0026rsquo;re writing code for computing the Softmax function in practice, the intermediate terms \\(e^{f_{y_i}}\\) and \\(\\sum_j e^{f_j}\\) may be very large due to the exponentials. Dividing large numbers can be numerically unstable, so it is important to use a normalization trick. Notice that if we multiply the top and bottom of the fraction by a constant \\(C\\) and push it into the sum, we get the following (mathematically equivalent) expression:\n$$ \\frac{e^{f_{y_i}}}{\\sum_j e^{f_j}} = \\frac{Ce^{f_{y_i}}}{C\\sum_j e^{f_j}} = \\frac{e^{f_{y_i} + \\log C}}{\\sum_j e^{f_j + \\log C}} $$\nWe are free to choose the value of \\(C\\). This will not change any of the results, but we can use this value to improve the numerical stability of the computation. A common choice for \\(C\\) is to set \\(\\log C = -\\max_j f_j \\). This simply states that we should shift the values inside the vector \\(f\\) so that the highest value is zero. In code:\nf = np.array([123, 456, 789]) # example with 3 classes and each having large scores p = np.exp(f) / np.sum(np.exp(f)) # Bad: Numeric problem, potential blowup # instead: first shift the values of f so that the highest number is 0: f -= np.max(f) # f becomes [-666, -333, 0] p = np.exp(f) / np.sum(np.exp(f)) # safe to do, gives the correct answer Possibly confusing naming conventions. To be precise, the SVM classifier uses the hinge loss, or also sometimes called the max-margin loss. The Softmax classifier uses the cross-entropy loss. The Softmax classifier gets its name from the softmax function, which is used to squash the raw class scores into normalized positive values that sum to one, so that the cross-entropy loss can be applied. In particular, note that technically it doesn\u0026rsquo;t make sense to talk about the \u0026ldquo;softmax loss\u0026rdquo;, since softmax is just the squashing function, but it is a relatively commonly used shorthand.\nSVM vs. Softmax See cs231: SVM vs. Softmax.\nReferences [1] Linear Classifier\n[2] Stanford CS229: Machine Learning Course\n","date":1549843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549843200,"objectID":"bd0ac0839e952f69a5aa1a6f19ef1a9a","permalink":"/post/2019-02-11-linear-classifier/","publishdate":"2019-02-11T00:00:00Z","relpermalink":"/post/2019-02-11-linear-classifier/","section":"post","summary":"Starting with the linear classifier Model Linear classifier computes scores $s = W x$ for $k$ different visual categories given the image, where $W$ was a matrix and $x$ was an input column vector containing all pixel data of the image. In the case of CIFAR-10, $x$ is a [3072x1] column vector, and $W$ is a [10x3072] matrix, so that the output scores is a vector of 10 class scores.","tags":["Supervised Learning","Classification","Linear"],"title":"Linear Classifier","type":"post"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nA fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Elynn Chen","Krishna Balasubramanian","Jianqing Fan"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"e4d79f53eee9e4777f3194a4ed0284e0","permalink":"/publication/bala-2019-eigenmatrix/","publishdate":"2019-06-02T02:25:10.622295Z","relpermalink":"/publication/bala-2019-eigenmatrix/","section":"publication","summary":"","tags":null,"title":"Low-Rank Principal Eigenmatrix Analysis","type":"publication"},{"authors":["Elynn Chen","Rong Chen"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"916832b494ec585438964de6d6311a33","permalink":"/publication/chen-2019-modeling/","publishdate":"2019-06-02T02:10:20.461104Z","relpermalink":"/publication/chen-2019-modeling/","section":"publication","summary":"","tags":null,"title":"Modeling Dynamic Transport Network with Matrix Factor Models: with an Application to International Trade Flow","type":"publication"}]